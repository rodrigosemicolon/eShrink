{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (Detecting depressed subjects)\n",
    "### Using contextualized language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_FILE = \"../posts.csv\"\n",
    "TRAIN_TOKEN=\"../train_df.csv\"\n",
    "TEST_TOKEN=\"../test_df.csv\"\n",
    "GENERAL_MODELS=\"../Models\"\n",
    "ROLLING_WINDOW_SIZE=10\n",
    "LM_MODEL='all-mpnet-base-v2'\n",
    "#'all-MiniLM-L6-v2'  'all-mpnet-base-v2'\n",
    "TASK=2\n",
    "CONVERTED=True\n",
    "SENT_MEASURED=True\n",
    "BASELINE_COMP=False\n",
    "MODEL_PATH =f\"{GENERAL_MODELS}/LM/win_{ROLLING_WINDOW_SIZE}_{LM_MODEL}\" \n",
    "max_lengths={1:64,3:128,5:256,10:512}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(MODEL_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opening resulting dataset with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(df, window_size,stride, field):\n",
    "    res_map={}\n",
    "    for user in df['User'].unique():\n",
    "        user_df = df[df['User']==user]\n",
    "        res_map[user]=(user_df['Label'].values[0],{})\n",
    "        posts = user_df[field].values\n",
    "        iteration=0\n",
    "        for i in range(0,len(posts),stride):\n",
    "            res_map[user][1][iteration]=' '.join((posts[i:i+window_size]))\n",
    "            iteration+=1\n",
    "    result_df = pd.DataFrame([(k,k1,v1,v[0]) for k,v in res_map.items() for k1,v1 in v[1].items()], columns = ['User','Window_id','Text','Label'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Store sentences & embeddings on disc\n",
    "def save_embeddings(filepath, embeddings):\n",
    "    with open(filepath, \"wb\") as fOut:\n",
    "        pickle.dump({ 'embeddings': embeddings}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#Load sentences & embeddings from disc\n",
    "def load_embeddings(filepath):\n",
    "    with open(filepath, \"rb\") as fIn:\n",
    "        stored_data = pickle.load(fIn)\n",
    "        stored_embeddings = stored_data['embeddings']\n",
    "    return stored_embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "seed=23\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "if not SENT_MEASURED:\n",
    "    train_df = pd.read_csv(TRAIN_TOKEN, sep='\\t')\n",
    "    test_df = pd.read_csv(TEST_TOKEN, sep='\\t')\n",
    "    train_df = rolling_window(train_df,ROLLING_WINDOW_SIZE,1,'Raw')\n",
    "    test_df = rolling_window(test_df,ROLLING_WINDOW_SIZE,1,'Raw')\n",
    "\n",
    "    from textblob import TextBlob\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    train_df['TB'] = train_df['Text'].apply(lambda text: TextBlob(text).sentiment)\n",
    "    train_df['VADER'] = train_df['Text'].apply(lambda text: sia.polarity_scores(text))\n",
    "    train_df['polarity'] = train_df['TB'].apply(lambda tb: (tb[0]+1/2))\n",
    "    train_df['subjectivity'] = train_df['TB'].apply(lambda tb: tb[1])\n",
    "    train_df['negativity'] = train_df['VADER'].apply(lambda v: v['neg'])\n",
    "    train_df['positivity'] = train_df['VADER'].apply(lambda v: v['pos'])\n",
    "    train_df['neutrality'] = train_df['VADER'].apply(lambda v: v['neu'])\n",
    "    train_df['compound'] = train_df['VADER'].apply(lambda v: (v['compound']+1)/2)\n",
    "    train_df.drop(['VADER','TB'], inplace=True, axis=1)\n",
    "\n",
    "    test_df['TB'] = test_df['Text'].apply(lambda text: TextBlob(text).sentiment)\n",
    "    test_df['VADER'] = test_df['Text'].apply(lambda text: sia.polarity_scores(text))\n",
    "    test_df['polarity'] = test_df['TB'].apply(lambda tb: (tb[0]+1/2))\n",
    "    test_df['subjectivity'] = test_df['TB'].apply(lambda tb: tb[1])\n",
    "    test_df['negativity'] = test_df['VADER'].apply(lambda v: v['neg'])\n",
    "    test_df['positivity'] = test_df['VADER'].apply(lambda v: v['pos'])\n",
    "    test_df['neutrality'] = test_df['VADER'].apply(lambda v: v['neu'])\n",
    "    test_df['compound'] = test_df['VADER'].apply(lambda v: (v['compound']+1)/2)\n",
    "    test_df.drop(['VADER','TB'], inplace=True, axis=1)\n",
    "\n",
    "    train_df.to_pickle(f\"train_df_{ROLLING_WINDOW_SIZE}_sent.pkl\")\n",
    "    test_df.to_pickle(f\"test_df_{ROLLING_WINDOW_SIZE}_sent.pkl\")\n",
    "train_df = pd.read_pickle(f\"train_df_{ROLLING_WINDOW_SIZE}_sent.pkl\")\n",
    "test_df = pd.read_pickle(f\"test_df_{ROLLING_WINDOW_SIZE}_sent.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Window_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>negativity</th>\n",
       "      <th>positivity</th>\n",
       "      <th>neutrality</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_subject1345</td>\n",
       "      <td>0</td>\n",
       "      <td>so many unwanted smith fadeaways. mid range j...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.663051</td>\n",
       "      <td>0.516980</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.98315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_subject1345</td>\n",
       "      <td>1</td>\n",
       "      <td>mid range jumpers hey guys, celtics fan here p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650092</td>\n",
       "      <td>0.517633</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.98440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_subject1345</td>\n",
       "      <td>2</td>\n",
       "      <td>well he got number tonight so maybe he will b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588214</td>\n",
       "      <td>0.594881</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.75595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_subject1345</td>\n",
       "      <td>3</td>\n",
       "      <td>i mean he will get pinch hits and an occasion...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573929</td>\n",
       "      <td>0.588929</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.60815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_subject1345</td>\n",
       "      <td>4</td>\n",
       "      <td>yeah you are probably right. oh well.  i gues...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.626531</td>\n",
       "      <td>0.626531</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.63660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174168</th>\n",
       "      <td>subject9959</td>\n",
       "      <td>627</td>\n",
       "      <td>nothing like that clean house feeling  there i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834343</td>\n",
       "      <td>0.551515</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.28280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174169</th>\n",
       "      <td>subject9959</td>\n",
       "      <td>628</td>\n",
       "      <td>there is always that one coworker...  there is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174170</th>\n",
       "      <td>subject9959</td>\n",
       "      <td>629</td>\n",
       "      <td>there is always that one coworker you just can...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174171</th>\n",
       "      <td>subject9959</td>\n",
       "      <td>630</td>\n",
       "      <td>that moment when you realize you need a new jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174172</th>\n",
       "      <td>subject9959</td>\n",
       "      <td>631</td>\n",
       "      <td>as an artist, this speaks to me on so many lev...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174173 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    User  Window_id  \\\n",
       "0       test_subject1345          0   \n",
       "1       test_subject1345          1   \n",
       "2       test_subject1345          2   \n",
       "3       test_subject1345          3   \n",
       "4       test_subject1345          4   \n",
       "...                  ...        ...   \n",
       "174168       subject9959        627   \n",
       "174169       subject9959        628   \n",
       "174170       subject9959        629   \n",
       "174171       subject9959        630   \n",
       "174172       subject9959        631   \n",
       "\n",
       "                                                     Text  Label  polarity  \\\n",
       "0        so many unwanted smith fadeaways. mid range j...      1  0.663051   \n",
       "1       mid range jumpers hey guys, celtics fan here p...      1  0.650092   \n",
       "2        well he got number tonight so maybe he will b...      1  0.588214   \n",
       "3        i mean he will get pinch hits and an occasion...      1  0.573929   \n",
       "4        yeah you are probably right. oh well.  i gues...      1  0.626531   \n",
       "...                                                   ...    ...       ...   \n",
       "174168  nothing like that clean house feeling  there i...      0  0.834343   \n",
       "174169  there is always that one coworker...  there is...      0  0.818182   \n",
       "174170  there is always that one coworker you just can...      0  0.818182   \n",
       "174171  that moment when you realize you need a new jo...      0  0.818182   \n",
       "174172  as an artist, this speaks to me on so many lev...      0  1.000000   \n",
       "\n",
       "        subjectivity  negativity  positivity  neutrality  compound  \n",
       "0           0.516980       0.053       0.145       0.802   0.98315  \n",
       "1           0.517633       0.048       0.147       0.805   0.98440  \n",
       "2           0.594881       0.082       0.121       0.797   0.75595  \n",
       "3           0.588929       0.088       0.107       0.805   0.60815  \n",
       "4           0.626531       0.091       0.118       0.792   0.63660  \n",
       "...              ...         ...         ...         ...       ...  \n",
       "174168      0.551515       0.097       0.033       0.869   0.28280  \n",
       "174169      0.477273       0.000       0.000       1.000   0.50000  \n",
       "174170      0.477273       0.000       0.000       1.000   0.50000  \n",
       "174171      0.477273       0.000       0.000       1.000   0.50000  \n",
       "174172      0.500000       0.000       0.000       1.000   0.50000  \n",
       "\n",
       "[174173 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not CONVERTED:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(LM_MODEL)\n",
    "\n",
    "    model.max_seq_length = max_lengths[ROLLING_WINDOW_SIZE]\n",
    "    train_sentence_embeddings = model.encode(train_df['Text'],show_progress_bar=True,\\\n",
    "                output_value='sentence_embedding', batch_size=64,convert_to_numpy=True)\n",
    "\n",
    "    val_sentence_embeddings = model.encode(test_df['Text'],show_progress_bar=True,\\\n",
    "                output_value='sentence_embedding', batch_size=64,convert_to_numpy=True)\n",
    "\n",
    "    save_embeddings(f\"./train_sentence_embeddings_{LM_MODEL}_{ROLLING_WINDOW_SIZE}.pkl\",train_sentence_embeddings)\n",
    "    save_embeddings(f\"./val_sentence_embeddings_{LM_MODEL}_{ROLLING_WINDOW_SIZE}.pkl\",val_sentence_embeddings)\n",
    "else:\n",
    "    train_sentence_embeddings = load_embeddings(f\"./train_sentence_embeddings_{LM_MODEL}_{ROLLING_WINDOW_SIZE}.pkl\")\n",
    "    val_sentence_embeddings = load_embeddings(f\"./val_sentence_embeddings_{LM_MODEL}_{ROLLING_WINDOW_SIZE}.pkl\")\n",
    "   \n",
    "test_df['Vector'] = pd.DataFrame(data=val_sentence_embeddings).values.tolist()\n",
    "train_df['Vector'] = pd.DataFrame(data=train_sentence_embeddings).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_df = pd.concat([train_df,test_df])\n",
    "full_df = full_df.sample(frac=1, random_state=seed).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Store sentences & embeddings on disc\n",
    "def save_embeddings(filepath, embeddings):\n",
    "    with open(filepath, \"wb\") as fOut:\n",
    "        pickle.dump({ 'embeddings': embeddings}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#Load sentences & embeddings from disc\n",
    "def load_embeddings(filepath):\n",
    "    with open(filepath, \"rb\") as fIn:\n",
    "        stored_data = pickle.load(fIn)\n",
    "        stored_embeddings = stored_data['embeddings']\n",
    "    return stored_embeddings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model(model, name):\n",
    "    with open(f\"{MODEL_PATH}/{name}\",'wb') as f:\n",
    "        pickle.dump( model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "def custom_cv(model, df, n_folds=5,sent =False):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    user_label_df =df.drop_duplicates('User')\n",
    "    users = user_label_df['User'].to_numpy()\n",
    "    \n",
    "    labels = user_label_df['Label'].to_numpy()\n",
    "    \n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(users, labels):\n",
    "        train_users = [users[f] for f in train_index]\n",
    "        test_users = [users[f] for f in test_index]\n",
    "\n",
    "        train_folds = df[df['User'].isin(train_users)].copy()\n",
    "        test_folds = df[df['User'].isin(test_users)].copy()\n",
    "\n",
    "        X_train = pd.DataFrame(train_folds['Vector'].values.tolist(), index = train_folds.index)\n",
    "        y_train = train_folds['Label']\n",
    "        X_test = pd.DataFrame(test_folds['Vector'].values.tolist(), index = test_folds.index)\n",
    "        \n",
    "        y_test = test_folds['Label']\n",
    "        if sent:\n",
    "            X_train = np.c_[X_train,train_folds['polarity'],train_folds['subjectivity'],train_folds['negativity'],train_folds['positivity'],train_folds['neutrality'], train_folds['compound']] \n",
    "            X_test = np.c_[X_test,test_folds['polarity'],test_folds['subjectivity'],test_folds['negativity'],test_folds['positivity'],test_folds['neutrality'], test_folds['compound']] \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        f1_scores.append(f1_score(y_test,model.predict(X_test)))\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "models = {\n",
    "        'sgdLR':SGDClassifier(random_state=seed,loss='log'),\n",
    "        'sgdlSVM':SGDClassifier(random_state=seed,loss='hinge'),\n",
    "        'ExtraTrees':ExtraTreesClassifier(random_state=seed,n_jobs=-1),\\\n",
    "        'Perceptron':Perceptron(random_state=seed)}\n",
    "if BASELINE_COMP:\n",
    "        report=\"\"\n",
    "        best_model_name = \"\"\n",
    "        best_model=None\n",
    "        best_f1=0\n",
    "        for model_name, model in models.items():\n",
    "                res = custom_cv(model,full_df)\n",
    "                if np.mean(res) > best_f1:\n",
    "                        best_f1=np.mean(res)\n",
    "                        best_model_name=model_name\n",
    "                        best_model=model\n",
    "                report+=f\"{model_name} f1: {round(np.mean(res),3)}\\n\"\n",
    "                print(f\"{model_name} f1: {round(np.mean(res),3)}\")\n",
    "        with open(f\"{MODEL_PATH}/baseline_report_{LM_MODEL}.txt\",'w') as f:\n",
    "                f.write(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASELINE_COMP:\n",
    "        res = custom_cv(best_model,full_df, sent=True)\n",
    "        print(f\"{best_model_name} f1: {round(np.mean(res),3)}\")\n",
    "\n",
    "        with open(f\"{MODEL_PATH}/baseline_report_{LM_MODEL}.txt\",'a') as f:\n",
    "                f.write(f\"\\nBest model with sent:\\n{best_model_name} f1: {round(np.mean(res),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best performing model was sgd Logistic Regression for window size 10, using MPNet without SA features, having achieved a 0.667 F1 score.\n",
    "#### But we didn't consider to be worth taking so much extra time training with MPNet features when MiniLm achieved very similar performance with nearly half the amount of features (F1=0.663 sgdLR, no SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "def train_eval_tuning(trial,params, df, sent=False):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    user_label_df =df.drop_duplicates('User')\n",
    "    users = user_label_df['User'].to_numpy()\n",
    "    \n",
    "    labels = user_label_df['Label'].to_numpy()\n",
    "\n",
    "    \n",
    "    f1_scores = []\n",
    "    for fold,(train_index, test_index) in enumerate(skf.split(users, labels)):\n",
    "        train_users = [users[f] for f in train_index]\n",
    "        test_users = [users[f] for f in test_index]\n",
    "\n",
    "        train_folds = df[df['User'].isin(train_users)]\n",
    "        X_train = pd.DataFrame(train_folds['Vector'].values.tolist(), index = train_folds.index)\n",
    "\n",
    "        test_folds = df[df['User'].isin(test_users)]\n",
    "        X_test = pd.DataFrame(test_folds['Vector'].values.tolist(), index = test_folds.index)\n",
    "\n",
    "        model = SGDClassifier(**params)\n",
    "        if sent:\n",
    "            X_train = np.c_[X_train,train_folds['polarity'],train_folds['subjectivity'],train_folds['negativity'],train_folds['positivity'],train_folds['neutrality'], train_folds['compound']] \n",
    "            X_test = np.c_[X_test,test_folds['polarity'],test_folds['subjectivity'],test_folds['negativity'],test_folds['positivity'],test_folds['neutrality'], test_folds['compound']] \n",
    "            \n",
    "\n",
    "        model.fit(X_train, train_folds['Label'])\n",
    "        f1_scores.append(f1_score(test_folds['Label'],model.predict(X_test)))\n",
    "    \n",
    "        trial.report(np.mean(f1_scores), fold)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_objective(trial):\n",
    "    parameters = {\n",
    "        'max_iter':trial.suggest_int('max_iter',1000,2500,step=500),\n",
    "        'loss':trial.suggest_categorical('loss',['log']),\n",
    "        'penalty':trial.suggest_categorical('penalty',['l2','l1','elasticnet']),\n",
    "        'alpha': trial.suggest_float('alpha',0.00001,0.1,log=True),\n",
    "        'random_state':trial.suggest_int('random_state',seed,seed)\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "  \n",
    "    \n",
    "    avg_f1 = train_eval_tuning(trial,parameters,full_df, sent=False)\n",
    "    return np.mean(avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-14 09:42:35,769]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-07-14 09:46:43,832]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-07-14 09:50:13,205]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-07-14 10:24:38,583]\u001b[0m Trial 48 finished with value: 0.6655177122889699 and parameters: {'max_iter': 2000, 'loss': 'log', 'penalty': 'l1', 'alpha': 8.093351246200499e-05, 'random_state': 23}. Best is trial 7 with value: 0.6699096264182774.\u001b[0m\n",
      "\u001b[32m[I 2022-07-14 10:28:07,488]\u001b[0m Trial 49 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#study = optuna.create_study(\n",
    "#        study_name=f\"t{TASK}_tuning_{ROLLING_WINDOW_SIZE}\",\n",
    "#        direction='maximize')\n",
    "study.optimize(tuning_objective, n_trials=5, timeout=(60*60*12))\n",
    "joblib.dump(study,f\"t{TASK}_tuning_{ROLLING_WINDOW_SIZE}.pkl\")\n",
    "study = joblib.load(f\"t{TASK}_tuning_{ROLLING_WINDOW_SIZE}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_iter': 2500,\n",
       "  'loss': 'log',\n",
       "  'penalty': 'l1',\n",
       "  'alpha': 0.00011514817252370237,\n",
       "  'random_state': 23},\n",
       " 0.6699096264182774)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params, study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{MODEL_PATH}/baseline_report_{LM_MODEL}.txt\",'a') as f:\n",
    "                f.write(f\"\\nOptimized model f1: {round(study.best_value,3)}\\nparams: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdLR_params = study.best_trial.params\n",
    "\n",
    "final_model = SGDClassifier(**sgdLR_params)\n",
    "full_train = pd.DataFrame(full_df['Vector'].values.tolist(), index = full_df.index)\n",
    "\n",
    "final_model.fit(full_train, full_df['Label'])\n",
    "save_model(final_model, \"optimized_sgdLR.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98b9776bb1c906ffea5885633daef92fdfff9bdc53a036d784e355cfb10fec4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
